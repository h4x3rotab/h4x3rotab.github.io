<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: osx | h4x's memo]]></title>
  <link href="http://h4x3rotab.github.io/blog/categories/osx/atom.xml" rel="self"/>
  <link href="http://h4x3rotab.github.io/"/>
  <updated>2015-01-10T13:28:38+08:00</updated>
  <id>http://h4x3rotab.github.io/</id>
  <author>
    <name><![CDATA[h4x3rotab]]></name>
    <email><![CDATA[h4x3rotab@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OS X下搭建虚拟Hadoop 2.5开发环境]]></title>
    <link href="http://h4x3rotab.github.io/blog/2014/12/05/os-xxia-da-jian-xu-ni-hadoop-2-dot-5kai-fa-huan-jing/"/>
    <updated>2014-12-05T07:00:31+08:00</updated>
    <id>http://h4x3rotab.github.io/blog/2014/12/05/os-xxia-da-jian-xu-ni-hadoop-2-dot-5kai-fa-huan-jing</id>
    <content type="html"><![CDATA[<p>在此记录OS X下搭建虚拟Hadoop 2.5开发环境，这包括了：</p>

<ol>
<li>Hadoop 2.5的安装、配置</li>
<li>访问Hadoop文件系统和运行样例</li>
<li>Intellij IDEA中创建Hadoop依赖的项目</li>
</ol>


<p>注意，OS X并不被Hadoop官方支持，因此仅可作为开发环境。</p>

<h1>0. 基本配置</h1>

<ul>
<li>OS X Yosemite 10.10.1</li>
<li>JDK 1.7</li>
<li>Hadoop 2.5.1 (from Homebrew)</li>
<li>Intellij IDEA 13 CE</li>
</ul>


<h1>1. 安装和配置</h1>

<ol>
<li><p>从<a href="http://brew.sh">Homebrew</a>安装Hadoop</p>

<pre><code> brew install hadoop
</code></pre>

<p> Homebrew包默认安装至<code>/usr/local/Cellar/hadoop</code>目录中，
 本文中安装的版本为Hadoop 2.5.2。</p>

<p> Hadoop从2.3版本开始引入Yarn核心，配置方式与此前版本不同。</p></li>
<li><p>进入配置文件目录</p>

<pre><code> cd /usr/local/Cellar/hadoop/2.5.2/libexec/etc/hadoop
</code></pre></li>
<li><p>修改<code>core-site.xml</code></p>

<p> 在<code>&lt;configuration&gt;</code>节点内添加以下配置。</p>

<p> <!-- language: lang-xml --></p>

<pre><code> &lt;property&gt;
     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
     &lt;value&gt;/Users/you_username/hadoop/tmp/hadoop-${user.name}&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
     &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
 &lt;/property&gt;
</code></pre>

<ul>
<li><p><code>hadoop.tmp.dir</code>: HDFS文件系统的存放位置，需要指定一个已
                  存在并有读写权限的文件夹。不过路径最后
                  一项是Hadoop自己创建的。</p></li>
<li><p><code>fs.defaultFS</code>: HDFS位置，写本机地址，9000是默认端口，可
                省略。</p></li>
</ul>
</li>
<li><p>修改<code>hdfs-site.xml</code></p>

<p> <!-- language: lang-xml --></p>

<pre><code> &lt;property&gt;
     &lt;name&gt;dfs.repliacation&lt;/name&gt;
     &lt;value&gt;1&lt;/value&gt;
 &lt;/property&gt;
</code></pre>

<ul>
<li><code>dfs.repliacation</code>: 文件副本数量，设为集群机器数。虚拟环境
                    中设为1.</li>
</ul>
</li>
<li><p>修改<code>yarn-site.xml</code></p>

<p> <!-- language: lang-xml --></p>

<pre><code> &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &lt;/property&gt;
</code></pre>

<p> 抄的，我也不知道具体有什么用。</p></li>
<li><p>复制<code>mapred-site.xml.template</code>，命名<code>mapred-site.xml</code></p>

<p> <!-- language: lang-xml --></p>

<pre><code> &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt;
 &lt;/property&gt;
</code></pre>

<ul>
<li><code>mapreduce.framework.name</code>: 设置Map-Reduce框架，此处选Yarn。</li>
</ul>
</li>
</ol>


<h1>2. 运行后台服务</h1>

<p>在运行之前，确保前面设置的Hadoop文件系统对应的目录已经准备好，
并且目录是空的。然后初始化HDFS文件系统：</p>

<pre><code>hdfs namenode -format
</code></pre>

<p>开启后台服务：</p>

<pre><code>start-dfs.sh
start-yarn.sh
</code></pre>

<p>关闭后台服务：</p>

<pre><code>stop-yarn.sh
stop-dfs.sh
</code></pre>

<p>后台服务启动后，可以通过<code>http://localhost:50070</code>监视运行状态。
同时，在命令行中可以用<code>jps</code>查看Hadoop服务启动是否正确。</p>

<p>例如，<code>jps</code>命令中不存在<code>DataNode</code>，则可能是执行</p>

<pre><code>hdfs namenode -foramt
</code></pre>

<p>之前没有清空设定的目录。</p>

<h1>3. 访问HDFS</h1>

<p>常用命令：</p>

<pre><code>hadoop fs -ls [&lt;path&gt;]
hadoop fs -mkdir &lt;path&gt;
hadoop fs -mv &lt;path&gt;
hadoop fs -rm &lt;path&gt;
hadoop fs -put &lt;local-path&gt; &lt;hdfs-path&gt;
hadoop fs -get &lt;hdfs-path&gt; &lt;local-path&gt;
hadoop fs -help
</code></pre>

<p>简单的浏览可以直接通过浏览器：</p>

<pre><code>http://localhost:50070
</code></pre>

<h1>4. 运行测试样例</h1>

<p>假定后台服务已启动，而且已经在Hadoop的安装目录中，可以执行PI测试：</p>

<pre><code>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.2.jar pi 20 10
</code></pre>

<p>如果执行成功，最后会显示一个极其粗糙的PI值。</p>

<h1>5. Intellij IDEA中配置依赖</h1>

<ol>
<li><p>创建普通Java项目</p></li>
<li><p>添加引用</p>

<ol>
<li><p><code>File</code> &ndash; <code>Project Structure...</code> &ndash; <code>Modules</code> &ndash; <code>Dependencies</code> &ndash;
<code>+</code> &ndash; <code>Library...</code> &ndash; <code>Java</code></p></li>
<li><p>选择<code>/usr/local/Cellar/hadoop/2.5.2/libexec/share/hadoop</code>
目录下除了<code>httpfs</code>外的全部文件夹。</p></li>
<li><p><code>Name</code>可以随便写，例如"common"，OK。</p></li>
<li><p><code>+</code> &ndash; <code>Jars or directories...</code></p></li>
<li><p>选择<code>/usr/local/Cellar/hadoop/2.5.2/libexec/share/hadoop/common/lib</code></p></li>
</ol>


<p> 此时<code>Dependencies</code>内应该总共增加了一个"common"和一个"lib"目录。</p></li>
<li><p>修改<code>Project Structure</code>中的<code>Artifacts</code>，增加Jar包的生成配置。</p></li>
</ol>


<p>可以写代码编译打包了。</p>
]]></content>
  </entry>
  
</feed>
